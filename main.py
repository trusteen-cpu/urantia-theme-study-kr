import streamlit as st
import os
import re
from openai import OpenAI

# -----------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------
st.set_page_config(page_title="ìœ ë€ì‹œì•„ ì£¼ì œ ì—°êµ¬ â€“ Korean", layout="wide")
st.title("ğŸ“˜ ìœ ë€ì‹œì•„ ì£¼ì œ ì—°êµ¬ â€“ Korean Edition")
st.caption("í•œê¸€ ìœ ë€ì‹œì•„ì„œ ë³¸ë¬¸ì—ì„œ ì£¼ì œë¥¼ ì°¾ì•„ AIê°€ ë³´ê³ ì„œì™€ ìŠ¬ë¼ì´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

# -----------------------
# API Key (Render í™˜ê²½ ë³€ìˆ˜)
# -----------------------
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Render í™˜ê²½ ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    st.stop()

# -----------------------
# íŒŒì¼ ê²½ë¡œ ì„¤ì •
# -----------------------
DATA_DIR = "data"
CANDIDATE_FILES = ["urantia_ko.txt", "urantia_kr.txt", "urantia.txt"]

def find_existing_path():
    for name in CANDIDATE_FILES:
        path = os.path.join(DATA_DIR, name)
        if os.path.exists(path):
            return path
    return None

KR_PATH = find_existing_path()

# -----------------------
# íŒŒì¼ ì½ê¸°
# -----------------------
def safe_read_text(path: str) -> list[str]:
    """íŒŒì¼ ì¸ì½”ë”© ë¬¸ì œë¥¼ ë°©ì§€í•˜ë©° ì•ˆì „í•˜ê²Œ ì½ê¸°"""
    encodings = ["utf-8", "utf-8-sig", "cp949", "euc-kr", "latin-1"]
    for enc in encodings:
        try:
            with open(path, "r", encoding=enc) as f:
                lines = f.readlines()
                cleaned = [l.replace("\ufeff", "").rstrip("\r\n") for l in lines if l.strip()]
                return cleaned
        except Exception:
            continue
    return []

@st.cache_data
def load_urantia_kr():
    if not KR_PATH:
        return []
    return safe_read_text(KR_PATH)

urantia_lines = load_urantia_kr()

# -----------------------
# ê²€ìƒ‰ í•¨ìˆ˜
# -----------------------
def search_passages(keyword: str, lines: list[str], limit: int = 200):
    if not keyword:
        return []
    key = keyword.strip()
    try:
        pattern = re.compile(re.escape(key))
    except re.error:
        pattern = re.compile(key)

    results = []
    for i, line in enumerate(lines, 1):
        clean_line = line.replace("\ufeff", "")
        if re.search(pattern, clean_line):
            results.append(f"{i}: {clean_line}")
    return results[:limit]

# -----------------------
# GPT ë³´ê³ ì„œ ìƒì„±
# -----------------------
def generate_gpt_report_and_slides(term: str, passages: list[str]):
    client = OpenAI(api_key=api_key)
    joined_passages = "\n".join(passages) or "ê´€ë ¨ êµ¬ì ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    prompt = f"""
ë‹¹ì‹ ì€ ìœ ë€ì‹œì•„ì„œë¥¼ ì—°êµ¬í•˜ëŠ” ì‹ í•™ìì…ë‹ˆë‹¤.

ì£¼ì œ: "{term}"

ì•„ë˜ëŠ” ì´ ì£¼ì œì™€ ê´€ë ¨ ìˆë‹¤ê³  íŒë‹¨ë˜ëŠ” ìœ ë€ì‹œì•„ì„œ ë³¸ë¬¸ì…ë‹ˆë‹¤.

---

## 1ë¶€. ì‹ í•™ì  ë³´ê³ ì„œ (700~1000ì)
- ì´ ì£¼ì œì˜ ìœ ë€ì‹œì•„ì  ì˜ë¯¸
- ì‹ ì„±/ìš°ì£¼ë¡ ì  ì¤‘ìš”ì„±
- ì•„ë²„ì§€, ìµœê·¹ì¡´
