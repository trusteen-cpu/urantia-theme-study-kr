import streamlit as st
import os
import re
from html import escape

# -----------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------
st.set_page_config(page_title="ìœ ë€ì‹œì•„ ì£¼ì œ ì—°êµ¬ â€“ í•œêµ­ì–´íŒ", layout="wide")

st.markdown("""
# ğŸ“˜ ìœ ë€ì‹œì•„ ì£¼ì œ ì—°êµ¬ (Urantia Theme Study â€“ Korean Edition)
ì…ë ¥í•œ ì£¼ì œì™€ ê´€ë ¨ëœ ìœ ë€ì‹œì•„ì„œ êµ¬ì ˆì„ ì°¾ì•„ì„œ,  
AIê°€ **ì£¼ì œ ë³´ê³ ì„œ**ì™€ **5ì¥ì§œë¦¬ ìŠ¬ë¼ì´ë“œ ê°œìš”**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
""")

# -----------------------
# ğŸ”‘ í™˜ê²½ ë³€ìˆ˜ì—ì„œ API Key ë¶ˆëŸ¬ì˜¤ê¸°
# -----------------------
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. Render ë˜ëŠ” GitHub Secretsì— ë“±ë¡í•´ì£¼ì„¸ìš”.")
    st.stop()

# -----------------------
# ë°ì´í„° ë¡œë“œ
# -----------------------
DATA_DIR = "data"
KR_PATH = os.path.join(DATA_DIR, "urantia_kr.txt")

import chardet  # â† ë§¨ ìœ„ import ëª©ë¡ì— ì¶”ê°€!

def safe_read_text(path: str) -> list[str]:
    """íŒŒì¼ ì¸ì½”ë”©ì„ ìë™ ê°ì§€í•˜ì—¬ ì˜¬ë°”ë¥´ê²Œ ì½ê¸°"""
    try:
        with open(path, "rb") as f:
            raw = f.read()
            enc = chardet.detect(raw)["encoding"] or "utf-8"
            text = raw.decode(enc, errors="ignore")
            # ì¤„ ë‹¨ìœ„ ë¶„ë¦¬, BOM ì œê±°
            lines = [l.replace("\ufeff", "").strip() for l in text.splitlines() if l.strip()]
            return lines
    except Exception as e:
        print("íŒŒì¼ ì½ê¸° ì˜¤ë¥˜:", e)
        return []

@st.cache_data
def load_urantia_kr():
    if not os.path.exists(KR_PATH):
        return []
    return safe_read_text(KR_PATH)

urantia_lines = load_urantia_kr()

# -----------------------
# ê²€ìƒ‰ ë° í•˜ì´ë¼ì´íŠ¸
# -----------------------
def highlight_term(text: str, term: str) -> str:
    """ê²€ìƒ‰ëœ ìš©ì–´ë¥¼ í˜•ê´‘ìƒ‰ìœ¼ë¡œ ê°•ì¡°"""
    if not term:
        return escape(text)
    pattern = re.compile(re.escape(term), re.IGNORECASE)
    highlighted = pattern.sub(lambda m: f"<mark style='background-color:#fffd75'>{escape(m.group(0))}</mark>", text)
    return highlighted

def search_passages(keyword: str, lines: list[str], limit: int = 200):
    if not keyword:
        return []

    # ê²€ìƒ‰ì–´ ì •ë¦¬ (ê³µë°±, BOM ì œê±°)
    key = keyword.strip().replace("\ufeff", "")

    # ì •ê·œì‹ íŒ¨í„´: í‚¤ì›Œë“œê°€ ë‹¨ì–´ ë‚´ë¶€ì— í¬í•¨ë˜ì–´ë„ ë§¤ì¹­
    try:
        pattern = re.compile(key)
    except re.error:
        pattern = re.compile(re.escape(key))

    results = []
    for i, l in enumerate(lines, 1):
        clean_line = l.strip().replace("\ufeff", "")  # BOM ì œê±°
        if re.search(pattern, clean_line):
            # ì ˆ ë²ˆí˜¸ + ë³¸ë¬¸ í‘œì‹œ
            results.append(f"{i}: {clean_line}")

    return results[:limit]


# -----------------------
# GPT ë³´ê³ ì„œ ë° ìŠ¬ë¼ì´ë“œ ìƒì„±
# -----------------------
def generate_gpt_report_and_slides(term: str, passages: list[str]):
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
    except Exception as e:
        return f"âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì˜¤ë¥˜: {e}"

    joined_passages = "\n".join(passages) or "ê´€ë ¨ êµ¬ì ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    prompt = f"""
ë‹¹ì‹ ì€ ìœ ë€ì‹œì•„ì„œì˜ ë‚´ìš©ì„ í•´ì„í•˜ê³  ê°€ë¥´ì¹˜ëŠ” ì‹ í•™ìì…ë‹ˆë‹¤.

ì£¼ì œ: "{term}"

ì•„ë˜ëŠ” ìœ ë€ì‹œì•„ì„œì—ì„œ ì´ ì£¼ì œì™€ ê´€ë ¨ëœ êµ¬ì ˆë“¤ì…ë‹ˆë‹¤.

---

## 1ë¶€. ì‹ í•™ì  ë³´ê³ ì„œ (700~1000ì)
- ì´ ì£¼ì œì˜ ìœ ë€ì‹œì•„ì  ì˜ë¯¸ì™€ ê¸°ì›  
- ì‹ ì„±, ìš°ì£¼ë¡ ì  ê´€ì ì—ì„œì˜ ì¤‘ìš”ì„±  
- ì•„ë²„ì§€, ìµœìƒ ì¡´ì¬, ì¡°ì ˆìì™€ì˜ ê´€ê³„  
- ì¸ê°„ì˜ ìƒìŠ¹ ì²´í—˜ê³¼ ì² í•™ì  í•¨ì˜  
- ì¸ê°„ ì‹ ì•™ê³¼ ì‚¶ì— ì£¼ëŠ” êµí›ˆ

---

## 2ë¶€. ìŠ¬ë¼ì´ë“œ 5ì¥ ê°œìš”
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **ì •í™•íˆ 5ì¥ì˜ ìŠ¬ë¼ì´ë“œ**ë¥¼ ë§Œë“œì„¸ìš”.

ê° ìŠ¬ë¼ì´ë“œëŠ”:
- ì œëª© 1ì¤„  
- í•µì‹¬ ìš”ì  3~5ê°œ  
- `ë°œí‘œì ë…¸íŠ¸:` (300~500ì) â€” ì„¤ëª…ìš© ìš”ì•½ë¬¸

í˜•ì‹ ì˜ˆì‹œ:

# ìŠ¬ë¼ì´ë“œ 1: <ì œëª©>
- í•µì‹¬ í¬ì¸íŠ¸
- í•µì‹¬ í¬ì¸íŠ¸
ë°œí‘œì ë…¸íŠ¸: ...

# ìŠ¬ë¼ì´ë“œ 2: ...
...

---

### ì°¸ê³  êµ¬ì ˆ:
{joined_passages}
"""

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ìœ ë€ì‹œì•„ì„œ ì‹ í•™ê³¼ êµìœ¡ì— ëŠ¥í†µí•œ í•™ìì´ë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )
        return resp.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ GPT ì˜¤ë¥˜ ë°œìƒ: {e}"

# -----------------------
# UI
# -----------------------
st.header("1ï¸âƒ£ ì£¼ì œ ì…ë ¥")
term = st.text_input("ì˜ˆ: ìµœìƒ ì¡´ì¬, ì‹ ì„±, ìƒê° ì¡°ì ˆì, ì‹ ì•™, ìƒìŠ¹, ë¯¸ê°€ì—˜", "", key="kr_theme_input")

passages = search_passages(term, urantia_lines) if term else []

st.header("2ï¸âƒ£ ê´€ë ¨ ìœ ë€ì‹œì•„ì„œ êµ¬ì ˆ")
if not urantia_lines:
    st.error("ğŸ“‚ data/urantia_kr.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. data í´ë”ì— íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”.")
elif term and passages:
    for i, line in enumerate(passages, 1):
        st.markdown(f"<b>{i}.</b> {highlight_term(line, term)}", unsafe_allow_html=True)
elif term:
    st.info("ê´€ë ¨ êµ¬ì ˆì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë‹¨ì–´ë‚˜ ì£¼ì œë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”.")

st.header("3ï¸âƒ£ AI ë³´ê³ ì„œ + ìŠ¬ë¼ì´ë“œ ìƒì„±")
if st.button("âœ¨ ë³´ê³ ì„œ ë° ìŠ¬ë¼ì´ë“œ ìƒì„±", key="generate_btn_kr"):
    with st.spinner("AIê°€ ë³´ê³ ì„œì™€ ìŠ¬ë¼ì´ë“œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        result = generate_gpt_report_and_slides(term, passages)
    st.markdown(result)
else:
    st.info("ì£¼ì œë¥¼ ì…ë ¥í•˜ê³  ë²„íŠ¼ì„ ëˆŒëŸ¬ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì„¸ìš”.")
st.divider()
st.write("ğŸ“„ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ì¤„):")
for line in urantia_lines[:5]:
    st.text(line)
