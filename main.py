import streamlit as st
import os
import re
from html import escape

# -----------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------
st.set_page_config(page_title="ìœ ë€ì‹œì•„ ì£¼ì œ ì—°êµ¬ â€“ í•œêµ­ì–´íŒ", layout="wide")

st.markdown("""
# ğŸ“˜ ìœ ë€ì‹œì•„ ì£¼ì œ ì—°êµ¬ (Urantia Theme Study â€“ Korean Edition)
ì…ë ¥í•œ ì£¼ì œë¥¼ ìœ ë€ì‹œì•„ì„œ ë³¸ë¬¸ì—ì„œ ì°¾ì•„ì„œ  
AIê°€ **ì‹ í•™ì  ë³´ê³ ì„œ**ì™€ **5ì¥ì§œë¦¬ ìŠ¬ë¼ì´ë“œ ê°œìš”**ë¥¼ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.
""")

# -----------------------
# ğŸ”‘ API í‚¤
# -----------------------
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    st.error("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Render í™˜ê²½ ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

# -----------------------
# ë°ì´í„° ê²½ë¡œ (ko â†’ kr â†’ ê¸°ë³¸)
# -----------------------
DATA_DIR = "data"
CANDIDATE_FILES = [
    "urantia_ko.txt",
    "urantia_kr.txt",
    "urantia.txt",
]

def find_existing_path():
    for name in CANDIDATE_FILES:
        path = os.path.join(DATA_DIR, name)
        if os.path.exists(path):
            return path
    return None

KR_PATH = find_existing_path()

# -----------------------
# íŒŒì¼ ì½ê¸°
# -----------------------
def safe_read_text(path: str) -> list[str]:
    """ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„í•´ì„œ ì¤„ ë‹¨ìœ„ë¡œ ì½ê¸°"""
    encodings = ["utf-8", "utf-8-sig", "cp949", "euc-kr", "latin-1"]
    for enc in encodings:
        try:
            with open(path, "r", encoding=enc) as f:
                # ì¤„ë§ˆë‹¤ BOM ì œê±° + ê³µë°± ì œê±°
                return [line.replace("\ufeff", "").rstrip("\n") for line in f.readlines()]
        except:
            continue
    return []

@st.cache_data
def load_urantia_kr():
    if not KR_PATH:
        return []
    return safe_read_text(KR_PATH)

urantia_lines = load_urantia_kr()

# -----------------------
# ê²€ìƒ‰ í•¨ìˆ˜ (ì ˆë²ˆí˜¸ ë¶™ì´ê¸°)
# -----------------------
def search_passages(keyword: str, lines: list[str], limit: int = 200):
    if not keyword:
        return []
    key = keyword.strip().replace("\ufeff", "")
    try:
        pattern = re.compile(key)
    except re.error:
        pattern = re.compile(re.escape(key))

    results = []
    for i, line in enumerate(lines, 1):
        clean_line = line.replace("\ufeff", "")
        if re.search(pattern, clean_line):
            results.append(f"{i}: {clean_line}")
    return results[:limit]

# -----------------------
# GPT ë³´ê³ ì„œ ìƒì„±
# -----------------------
def generate_gpt_report_and_slides(term: str, passages: list[str]):
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
    except Exception as e:
        return f"âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì˜¤ë¥˜: {e}"

    joined_passages = "\n".join(passages) or "ê´€ë ¨ êµ¬ì ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    prompt = f"""
ë‹¹ì‹ ì€ ìœ ë€ì‹œì•„ì„œë¥¼ ì—°êµ¬í•˜ëŠ” ì‹ í•™ìì…ë‹ˆë‹¤.

ì£¼ì œ: "{term}"

ì•„ë˜ëŠ” ì´ ì£¼ì œì™€ ê´€ë ¨ ìˆë‹¤ê³  íŒë‹¨ë˜ëŠ” ìœ ë€ì‹œì•„ì„œ ë³¸ë¬¸ì…ë‹ˆë‹¤.

---

## 1ë¶€. ì‹ í•™ì  ë³´ê³ ì„œ (700~1000ì)
- ì´ ì£¼ì œì˜ ìœ ë€ì‹œì•„ì  ì˜ë¯¸
- ì‹ ì„±/ìš°ì£¼ë¡ ì  ì¤‘ìš”ì„±
- ì•„ë²„ì§€, ìµœê·¹ì¡´ì¬, ìƒê°ì¡°ìœ¨ìì™€ì˜ ê´€ê³„
- ì¸ê°„ ìƒìŠ¹ ì²´í—˜ê³¼ì˜ ì—°ê²°
- ì˜¤ëŠ˜ì˜ ì‹ ì•™ê³¼ ì‚¶ì— ì£¼ëŠ” êµí›ˆ

## 2ë¶€. 5ì¥ ìŠ¬ë¼ì´ë“œ ê°œìš”
ê° ìŠ¬ë¼ì´ë“œëŠ”
- ì œëª© 1ì¤„
- í•µì‹¬ í¬ì¸íŠ¸ 3~5ê°œ
- `ë°œí‘œì ë…¸íŠ¸:` 300~500ì

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:

# ìŠ¬ë¼ì´ë“œ 1: ...
- ...
ë°œí‘œì ë…¸íŠ¸: ...

# ìŠ¬ë¼ì´ë“œ 2: ...
...

---

### ì°¸ê³  ë³¸ë¬¸:
{joined_passages}
"""

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ìœ ë€ì‹œì•„ì„œ ì‹ í•™ê³¼ êµìœ¡ì— ëŠ¥í†µí•œ í•™ìì´ë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )
        return resp.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ GPT ì˜¤ë¥˜ ë°œìƒ: {e}"

# -----------------------
# UI
# -----------------------
st.header("1ï¸âƒ£ ì£¼ì œ ì…ë ¥")
term = st.text_input("ì˜ˆ: ì‹ ì„±, ìµœê·¹ì, ì¡°ìœ¨ì, ë¯¸ê°€ì—˜, ìƒìŠ¹, ì‹ ì•™", "", key="kr_theme_input")

st.header("2ï¸âƒ£ ê´€ë ¨ ìœ ë€ì‹œì•„ì„œ êµ¬ì ˆ")

if not KR_PATH:
    st.error("ğŸ“‚ data í´ë”ì— urantia_ko.txt ë˜ëŠ” urantia_kr.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í•˜ë‚˜ë¥¼ ì˜¬ë ¤ì£¼ì„¸ìš”.")
else:
    if not urantia_lines:
        st.error(f"âš ï¸ {KR_PATH} íŒŒì¼ì„ ì½ì—ˆì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì¸ì½”ë”©(utf-8, euc-kr) í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        passages = search_passages(term, urantia_lines) if term else []
        if term and passages:
            for p in passages:
                st.markdown(p)
        elif term:
            st.info("ê´€ë ¨ êµ¬ì ˆì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë‹¨ì–´ë‚˜ ì£¼ì œë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”.")

        # ë””ë²„ê·¸ìš© ë¯¸ë¦¬ë³´ê¸°
        st.divider()
        st.write("ğŸ“„ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ì¤„):")
        for line in urantia_lines[:5]:
            st.text(line)

st.header("3ï¸âƒ£ AI ë³´ê³ ì„œ + ìŠ¬ë¼ì´ë“œ ìƒì„±")
if st.button("âœ¨ ë³´ê³ ì„œ ë° ìŠ¬ë¼ì´ë“œ ìƒì„±", key="generate_btn_kr"):
    with st.spinner("AIê°€ ë³´ê³ ì„œì™€ ìŠ¬ë¼ì´ë“œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        passages = search_passages(term, urantia_lines) if term else []
        result = generate_gpt_report_and_slides(term, passages)
    st.markdown(result)
else:
    st.info("ì£¼ì œë¥¼ ì…ë ¥í•˜ê³  ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ AIê°€ ë‚´ìš©ì„ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.")

